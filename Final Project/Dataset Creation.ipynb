{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13e267dc-11b2-46f7-a539-3fe2766ec62a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Kyle Demers\n",
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f62b7-d95e-4ab3-87c1-e88d0578367d",
   "metadata": {},
   "source": [
    " 1) Sources of the dataset a. Where did you get the data? b. How did you get the data? c. What is the license of the data if any? e. Link to code used to create the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2900cc-3bba-4770-947f-285d6799f584",
   "metadata": {},
   "source": [
    "The data set it created by pulling tweets after every matchweek using the twitter handle of each premier league team. The tweets are pulled from a python package called Twarc2. We use [pull_tweets.py](https://github.com/Kyle-Demers08/NLP_340/blob/main/Final%20Project/python_scripts/pull_tweets.py) to pull the tweets. The search term is the premier league teams handle, and I have specified that the tweet should be in English and not have links or be retweets. Some links do however still sneak through, so we will deal with that in future preprocessing. We output all of the tweet metadata into a jsonl file to have a one line per object textfile to then pull tweets from. The jsonl file will be the same name as the teams twitter handle.\n",
    "\n",
    "We then pull the text of the tweet using [pull_text.py](https://github.com/Kyle-Demers08/NLP_340/blob/main/Final%20Project/python_scripts/pull_text.py). This script reads in each line(one object) and looks for the tweet key. It then checks to make sure there are no duplicates, and prints out the list. \n",
    "\n",
    "We run both these python scripts by using [get_all_tweets_about.py](https://github.com/Kyle-Demers08/NLP_340/blob/main/Final%20Project/python_scripts/Get_all_tweets_about.py). This script initializes a list of all the teams in the premier league. It then calls the pull_tweets python script to get tweets about each team. Then it pulls the text from the jsonl file and stores it in a txt file with the name being the teams handle.\n",
    "\n",
    "**Reiteration of the Goals**\n",
    "1) Be able to predict when a premier league manager will be sacked using sentiment analysis.\n",
    "\n",
    "The issue with this is that I have to manually go back in the twitter timeline to pull tweets from around that time. This is because twarc2 only allows pulling tweets from 7 days previous. A can create a small subset of those tweets and create a supervised learning model demonstrating which tweets are common before a manager gets sacked. Another issue is that another manager might not get sacked in the next few months so I would have to use old self gathered data.\n",
    "\n",
    "2) Try and use tweets about teams to see how many points they have earned \n",
    "\n",
    "This I think is a lot more likely, but I'm not sure how to use NLP for this. I might use sentiment analysis to predict if the tweets are good, neutral, or bad correlating to win, draw or loss. I will be able to have tweets from matchweek 26 - 36 in the time of this project. There are also match replays which is likely another game. Overall this is 11 games played which should be interesting to see how well the model can do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2966514-45d2-465a-8271-1bd007b61f38",
   "metadata": {},
   "source": [
    "If we look to see how many points each team has earned, we should see where they are standing before matchweek 26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623a3ee-2445-49ad-ac74-54c8867d6d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MW_26_points = {'bournemouth':21 , 'arsenal':60, 'villa':31, 'Brighton':35, 'Chelsea':31, 'spurs':45, 'crystal':27, 'everton':21, 'leicester':24, 'liverpool':39, 'leeds':22, 'manu':49, 'mancity':55, 'forest':25, 'newcastle':41, 'southhampton':18, 'westham':23, 'wolves':24,'fulham':39,'brentford':25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92448ca7-8d7f-4be6-9396-a685b8bd3455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import re\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e618a5-e17d-45b2-90cf-2955560f2b22",
   "metadata": {},
   "source": [
    "The first thing we need to do is get our tweets out from a folder and into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f3d8e2-7a96-49c5-81f3-711010f569d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gettweets(Matchweek) -> str:\n",
    "    '''\n",
    "    Matchweek: name of folder inside the data folder\n",
    "    \n",
    "    Pulls all of the tweets out of folder inside data/Matchweek ##\n",
    "    '''\n",
    "    md = {}\n",
    "    for filename in os.listdir(\"data/\" + Matchweek): #get the txt document for each team inside the folder data/ input:matchweek ##\n",
    "        try:\n",
    "            f = open(\"data/\" +Matchweek + '/' + filename, \"r\") #open each txt file\n",
    "        except:\n",
    "            OSError([21]) #catches .ipynbcheckpoints\n",
    "            continue\n",
    "        ts = f.read() #Read it in to a variable as a string\n",
    "        key = filename[0:-4] # drop the .txt so the keys are the club names\n",
    "        md[key] = ts #add the tweet info\n",
    "        #Need to create a tweet seperator. Txt file is a list. when we see \", or a ', that is the end of a tweet\n",
    "        # and the start of a new tweet. \n",
    "        md[key] = md[key].replace('\",', '<BREAK HERE>') \n",
    "        md[key] = md[key].replace(\"',\", '<BREAK HERE>')\n",
    "        md[key] = md[key].split(\"<BREAK HERE>\") #create a list from using the break here to find the break between tweets\n",
    "        #print(ts)\n",
    "        f.close()\n",
    "    return md "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35f1c3-ecb4-400b-a6d1-ed31e65704b9",
   "metadata": {},
   "source": [
    "There are a lot of tweets in here that we aren't interested in. For example, clickbait to a suspicious website won't tell us how you feel about the team. If you need to sell tickets because something came up won't give us sentiment. Let's remove these types of tweets. Also twitter handles and new line characters aren't relevant. While we will do more formal tokenization later, for now let's quickly get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3459ba-0fec-46c5-87e1-11c74193dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(tweets) -> list:\n",
    "    '''\n",
    "    tweets: list of tweets\n",
    "    \n",
    "    Remove links, Twitter handles, and new line characters from a list of tweets\n",
    "    '''\n",
    "    new = []\n",
    "    for i,txt in enumerate(tweets):\n",
    "        #catch anything that looks spam related or not relevant to sentiment and remove it from the tweets list\n",
    "        if 'https:' in txt: \n",
    "            continue\n",
    "        if 'http:' in txt:\n",
    "            continue\n",
    "        if '.com' in txt:\n",
    "            continue\n",
    "        if '.co' in txt:\n",
    "            continue\n",
    "        if 'trying to get premier league clubs to reply' in txt:\n",
    "            continue\n",
    "        if 'you changed my life financially' in txt:\n",
    "            continue\n",
    "        if ' Sign up for free' in txt:\n",
    "            continue\n",
    "        if 'selling ticket' in txt:\n",
    "            continue\n",
    "        txt = re.sub(r'@\\w+', '', txt) #remove handles\n",
    "        txt = re.sub(r'\\n', '', txt) #remove \\n character\n",
    "        new.append(txt)\n",
    "    return new "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280c38e-1ee8-48fb-abfd-e27cee19dc93",
   "metadata": {},
   "source": [
    "We also need a place to store these tweets. Let's create a pandas dataframe to store all of this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e14e412-8e47-4d38-9703-6945640b1820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df(team_dict) -> dict:\n",
    "    '''\n",
    "    team_dict: dictionary of all teams and their tweets\n",
    "    \n",
    "    creates a dataframe of the the teams and their tweets. It also initialize a wins loss and draws column\n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['Team', 'Tweet','Win','Draw','Loss']) #initialize a df\n",
    "    idx =0\n",
    "    for key in team_dict.keys(): #for every team\n",
    "        team_dict[key] = clean(team_dict[key]) #clean it\n",
    "        for tweet in team_dict[key]: #for every tweet\n",
    "            new_row = pd.DataFrame({'Team':key,'Tweet':tweet,'Win':0,'Draw':0,'Loss':0},index = [idx]) #make the row\n",
    "            df = pd.concat([df,new_row]) #insert it\n",
    "            idx+=1\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c13032-86d7-4983-a8fe-c4397e8755c7",
   "metadata": {},
   "source": [
    "To finish filling out this dataframe we need to insert the results from this matchweek incase we decide to do supervised learning in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05df033a-bc81-44d4-8af1-a6cf79d7a5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def insertwins(dictionary,df):\n",
    "    '''\n",
    "    dictionary: dictionary of results that should be updated manually before pushing\n",
    "    df: dataframe of teams and tweets filled out with empty Win, Draw, Loss columns\n",
    "    \n",
    "    Insert the results of the matchweek into the dataframe\n",
    "    '''\n",
    "    for key in dictionary.keys():\n",
    "        df.loc[df['Team'] == key,results[key]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65610061-d3ad-4361-a9f4-616dd195231b",
   "metadata": {},
   "source": [
    "Now let's use our functions to get data from matchweek 27!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb31abc7-d065-4ce5-8f21-bf6b037c6c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets = gettweets('Matchweek_27')\n",
    "df = make_df(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f26b18-d66c-487a-ac1c-ea5d0f310e69",
   "metadata": {},
   "source": [
    "## UPDATE EVERY WEEK!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "856c4d43-d250-40b1-8771-a983852aae23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {'afcbournemouth':'Loss','ArsenalFC':'Win','avfc':'Win', 'BHAFC':'Win','ChelseaFC':'Win','COYS':'Loss','CPFC':'Loss','everton':'Draw','lcfc':'Loss','lfc':'Win','LUFC':'Loss','manunited':'Loss','mcfc':'Win','NFFC':'Draw','NUFC':'Loss','SouthamptonFC':'Win','WHUFC':'Loss','WolvesFC':'Win','fulhamfc':'Loss','BrentfordFC':'Win'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "616e7f5c-0723-4b12-8d20-7c12093398ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Win</th>\n",
       "      <th>Draw</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fulhamfc</td>\n",
       "      <td>'  Passion towards your club?? Behave yoursel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fulhamfc</td>\n",
       "      <td>'  Lol . Was he just walking the streets afte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fulhamfc</td>\n",
       "      <td>'    SOON</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fulhamfc</td>\n",
       "      <td>' We were better when he called us “Cottage’s”</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fulhamfc</td>\n",
       "      <td>'      Who is the Batman for the soccer plays? 🤣</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>SouthamptonFC</td>\n",
       "      <td>'  No unfortunately</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>SouthamptonFC</td>\n",
       "      <td>\"    Played a blinder for Bournemouth at St A...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>SouthamptonFC</td>\n",
       "      <td>'  This is how u get blocked huh?😂</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>SouthamptonFC</td>\n",
       "      <td>'4 Mar 2023:  1-0 Leicester\\n\\n made his 330t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>SouthamptonFC</td>\n",
       "      <td>'   Sinking ship.']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Team                                              Tweet Win  \\\n",
       "0         fulhamfc   '  Passion towards your club?? Behave yoursel...   0   \n",
       "1         fulhamfc   '  Lol . Was he just walking the streets afte...   0   \n",
       "2         fulhamfc                                          '    SOON   0   \n",
       "3         fulhamfc     ' We were better when he called us “Cottage’s”   0   \n",
       "4         fulhamfc   '      Who is the Batman for the soccer plays? 🤣   0   \n",
       "..             ...                                                ...  ..   \n",
       "708  SouthamptonFC                                '  No unfortunately   1   \n",
       "709  SouthamptonFC   \"    Played a blinder for Bournemouth at St A...   1   \n",
       "710  SouthamptonFC                 '  This is how u get blocked huh?😂   1   \n",
       "711  SouthamptonFC   '4 Mar 2023:  1-0 Leicester\\n\\n made his 330t...   1   \n",
       "712  SouthamptonFC                                '   Sinking ship.']   1   \n",
       "\n",
       "    Draw Loss  \n",
       "0      0    1  \n",
       "1      0    1  \n",
       "2      0    1  \n",
       "3      0    1  \n",
       "4      0    1  \n",
       "..   ...  ...  \n",
       "708    0    0  \n",
       "709    0    0  \n",
       "710    0    0  \n",
       "711    0    0  \n",
       "712    0    0  \n",
       "\n",
       "[713 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insertwins(results,df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70daee6-d7e8-4851-ac49-942f70b34eeb",
   "metadata": {},
   "source": [
    "2) Description of the dataset a. What is the size of the dataset? b. What is the format of the dataset? c. What is the structure of the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a53b9-9bca-4737-a651-184303734f10",
   "metadata": {},
   "source": [
    "After removing a good chunk of tweets, the dataset looks like it is pulling a little over 700 total tweets which is about 35 tweets per Premier League team. This means if a manager is performing poorly for 4 weeks in a row we will have 140 tweets that are likely not so favorable in a row. This could be used to predict if the manager is being sacked. If we are looking to predict how a team does in the next 11 weeks we have 385 tweets per team and 7700 tweets total. This might be a little small, so after this week I will double the search size. \n",
    "\n",
    "I plan on storing all of these pandas dataframes as a csv so that the information isn't lost. The information in the csv is what is in the pandas dataframe being the Team, Tweet, Win, Draw, Loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe054d-3aa3-4d33-b351-f3ca973ff1b5",
   "metadata": {},
   "source": [
    "3 a. What are the data models used in the dataset? b. What are the data structures used in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75787bb-497f-4c8d-9d69-bff349043c82",
   "metadata": {},
   "source": [
    "In order to get the data from a csv file into a complete pandas dataframe I will read all the files into a sqlite database. From there I can simply union the databases into one complete database. The Tweets and teams are all stored as strings, and the wins, draws, losses are stored as integers. Below are the amount of tweets per team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4e06366-c485-43c6-9ce2-35f84a6bb00c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afcbournemouth has 30 tweets in the dataframe.\n",
      "ArsenalFC has 30 tweets in the dataframe.\n",
      "avfc has 59 tweets in the dataframe.\n",
      "BHAFC has 32 tweets in the dataframe.\n",
      "ChelseaFC has 53 tweets in the dataframe.\n",
      "COYS has 30 tweets in the dataframe.\n",
      "CPFC has 29 tweets in the dataframe.\n",
      "everton has 34 tweets in the dataframe.\n",
      "lcfc has 29 tweets in the dataframe.\n",
      "lfc has 83 tweets in the dataframe.\n",
      "LUFC has 29 tweets in the dataframe.\n",
      "manunited has 31 tweets in the dataframe.\n",
      "mcfc has 35 tweets in the dataframe.\n",
      "NFFC has 29 tweets in the dataframe.\n",
      "NUFC has 32 tweets in the dataframe.\n",
      "SouthamptonFC has 30 tweets in the dataframe.\n",
      "WHUFC has 30 tweets in the dataframe.\n",
      "WolvesFC has 29 tweets in the dataframe.\n",
      "fulhamfc has 30 tweets in the dataframe.\n",
      "BrentfordFC has 29 tweets in the dataframe.\n"
     ]
    }
   ],
   "source": [
    "for i in results.keys():\n",
    "    print(i + ' has ' + str(len(df.loc[df['Team']==i])) + ' tweets in the dataframe.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
