## Kyle Demers
**HW_1**

**Using Chat GPT for Linguistics Essay**

## Description:

The purpose of this assignment is to have you engage with the ChatGPT: https://chat.openai.com/chat. ChatGPT is an Large Language Model (175 billion parameters). Ask ChatGPT to write an essay about linguistics and NLP. Probe it to see whether it can recognize sources. Is ChatGPT aware of Brown Tags, dependency parsers, parts of speech? Is it's knowledge sound or accurate? Please provide the output from your chat and write a short response to ChatGPT.]

## Objective:

Learning how to utilize ChatGPT or Large Language models to boost your creativity, as well learn how to and what can be relied on as knowledge from Large Language Models.

## Work:

## Input 1:

Write an essay about linguistics and natural language processing

### Response:

Linguistics and natural language processing are two interrelated fields that study human language and the ways in which computers and machines can process and understand it. Linguistics is the scientific study of language and its structure, while natural language processing (NLP) is a branch of artificial intelligence that focuses on the development of algorithms and models that enable computers to understand, interpret, and generate human language.

Language is a complex and intricate system that allows humans to express their thoughts, ideas, and feelings. It is a uniquely human ability that has developed over thousands of years and has been the subject of much research and study in linguistics. Linguistics is concerned with understanding the underlying rules and structure of language, as well as the ways in which people use language to communicate. It covers a wide range of topics, from phonetics and phonology (the study of sounds in language) to syntax and semantics (the study of sentence structure and meaning), and everything in between.

One of the key goals of linguistics is to identify and describe the rules and patterns that govern the use of language. For example, linguists study the grammar of different languages and the ways in which words are combined to form sentences. They also investigate the meaning of words and how they are used to convey different emotions and attitudes. Additionally, linguists look at how language varies between different regions and communities, as well as how it changes over time.

In recent years, the field of linguistics has been influenced by the development of natural language processing. NLP is concerned with the development of computer algorithms that can process and understand human language. This field has grown rapidly in recent years, driven by the increased availability of large amounts of text data and advances in machine learning techniques. NLP applications are now used in a wide range of industries, from customer service and marketing to healthcare and finance.

NLP systems use a variety of techniques to process and understand human language. These techniques include text classification, sentiment analysis, named entity recognition, and machine translation. For example, a text classification system might be trained to categorize news articles based on their topic, while a sentiment analysis system might be used to determine the emotional tone of a piece of text.

One of the key challenges in NLP is to develop algorithms that can understand and interpret human language in a way that is comparable to the way humans do. This requires a deep understanding of the underlying structure of language and the ways in which words and sentences are combined to convey meaning. As a result, NLP researchers often draw on the insights and theories developed in linguistics to guide their work.

In conclusion, linguistics and NLP are two fields that are closely intertwined, with one building on the insights and theories of the other. Linguistics provides a deep understanding of the structure of human language and the ways in which it is used, while NLP focuses on the development of computer algorithms that can process and understand it. As the field of NLP continues to grow and evolve, it will likely play an increasingly important role in a wide range of industries and applications, and its relationship with linguistics will remain an essential one.

### Discussion:

Chat GPT seems to have a complete understanding about the topics of linguistics and NLP. The flow of the essay is sound and is something that could easily be seen as human.


## Input 2:

Can you cite your sources for that?

### Response:

I'm sorry, but as an AI language model I don't have sources to cite. My training data comes from a diverse range of text sources, including the web, books, and academic papers, but I don't have specific references for the information included in the essay. The information is based on general knowledge and understanding about the fields of linguistics and natural language processing, which are widely studied and discussed in both academic and industry circles.

### Discussion:

It seems that Chat GPT is not able to cite it's sources as it doesn't scrape articles for it's information. All of the response information has come from it's own massive training data

## Input 3:

are you aware of brown tags?

### Response

Yes, I am aware of Brown tags. The Brown Corpus is a widely-used corpus of text in computational linguistics and natural language processing. It was compiled in the early 1960s at Brown University and was one of the first large-scale language corpora to be created. The Brown Corpus is annotated with a set of part-of-speech tags, which are used to identify the grammatical role of each word in a sentence. These tags are known as Brown tags and are still widely used in NLP research today as a standard way of annotating text. The Brown Corpus and its associated tags have played an important role in the development of NLP and have been used in the development of many NLP tools and models.

### Discussion:

Chat GPT is aware of brown tags and even provided a bit of background for me.

## Input 4:

What about dependency parsers?

### Response

Yes, I am also aware of dependency parsers. A dependency parser is a tool used in natural language processing to analyze the grammatical structure of a sentence. It aims to identify the relationships between the words in a sentence, specifically the relationships between the head words and the dependent words.

Dependency parsing is an important task in NLP, as it provides a way to analyze the structure of sentences and to understand how words in a sentence are related to one another. The output of a dependency parser is a dependency parse tree, which is a graphical representation of the relationships between the words in a sentence. This information can then be used in a variety of NLP applications, such as information extraction, question answering, and machine translation.

There are many different algorithms and models used for dependency parsing, ranging from simple rule-based systems to complex machine learning models. The choice of algorithm or model often depends on the specific task and the resources available, as well as the accuracy and efficiency requirements of the system.

In conclusion, dependency parsing is an important task in NLP that provides a way to analyze the structure of sentences and to understand the relationships between the words in a sentence. It has many applications in NLP and has been the subject of much research and development in recent years.

### Discussion:

Chat GPT decided to essentially write another essay to answer this. What I find interesting is that I am asking if it is aware of something, and it returns a synopsis of my question. This isn't normally how humans would interact, at least not to the extent of Chat GPT's response

## Input 5:

What about parts of speech?

### Response:

Yes, I am aware of parts of speech (POS) as well. Parts of speech is a grammatical category assigned to words based on their role in a sentence and their relationship with other words. In English, the most common parts of speech are nouns, verbs, adjectives, adverbs, pronouns, prepositions, conjunctions, and interjections.

The identification of parts of speech is an important task in natural language processing (NLP), as it provides a way to analyze the structure of a sentence and to understand the relationships between words. This information can be used for many NLP tasks, such as text classification, named entity recognition, and machine translation.

There are many different algorithms and models used for POS tagging, including rule-based systems, statistical models, and machine learning models. The choice of algorithm or model often depends on the specific task and the resources available, as well as the accuracy and efficiency requirements of the system.

In conclusion, parts of speech is a grammatical category assigned to words that provides information about their role in a sentence and their relationship with other words. The identification of parts of speech is an important task in NLP and is used for a wide range of NLP applications.

### Discussion:

This has me feeling the same way about the 4th response. It seems that the first paragraph is fitting for my question, yet it provides another 3 for extra information.

## Conclusion:

Chat GPT certainly has a wealth of knowledge and can display it in well written text. My only flaw is that it's responses seem to be a bit long and exagerated. It seems to be sort of cocky in a way of how much knowledge it has and will provide an overload of information to any question.

